# test10

Отказоустойчивая система, с автоматизацией установки и настройки.
Состоять из следующих элементов:
- балансировщик нода 1 (nginx, pacemaker, corosync, crmsh)
- балансировщик нода 2 (nginx, pacemaker, corosync, crmsh)
- бэкэнд нода 1 (apache2)
- бэкэнд нода 2 (apache2)
- сервер автоматизации (ansible)


После скачивания заходим в папку Docker и выполняем для раскатки докер контейнеров:
docker compose -f docker-compose.yml up -d

Должны создасться контейнеры с данными именами:
балансировщик нода 1 -  web1     - 172.16.0.2
балансировщик нода 2 -  web2     - 172.16.0.3
бэкэнд нода 1 -         bec1     - 172.16.0.4
бэкэнд нода 2 -         bec2     - 172.16.0.5
сервер автоматизации -  ansible  - 172.16.0.6

VIP адрес - 172.16.0.10 - VipLb

1. playbook установки балансировщиков и их настройки.
2. playbook установки и настройки кластеризации балансировщиков.
3. playbook установки и настройки бэкенда.

После чего входим в конйтенер ansible "Для входа логин:пароль используем root:root".

docker exec -ti ansible bash

ВНИМАНИЕ: После раскатки через docker-compose нужно дождаться установки ansible в контейнере ansible, проверку установки можно проверить через какое то время командой "ansible --version", так же командой "top" можно посмотреть, когда закончаться процессы установки (должно остаться 3). 

В корне контейнера должна быть папка Ansible, входим в неё.
В этой папке находится 4 playbook выполняем запуск плейбука "playbook.yaml" который запустит последовательно остальные 3 плейбука.
ansible-playbook playbook.yaml

После того, как все плейбука отработали, можно для начала проверить, что отрабатываеют наши балансировщики
curl 172.16.0.2
curl 172.16.0.3
Должно высветиться сообщение <h1>Это backend1"</h1> или <h1>Это backend2"</h1>.

Потом можно проверить наши бекенды.
curl 172.16.0.4 #отобразится сообщение <h1>Это backend1"</h1>
curl 172.16.0.5 #отобразится сообщение <h1>Это backend2"</h1>

curl 172.16.0.10 #отобразится сообщение <h1>Это backend1"</h1 или <h1>Это backend2"</h1>

Выходим из контейнера ansible.
exit

Проверим состояние узла и состояния кластера через web1 или web2 контейнер и увидим, что всё работает.
docker exec web1 crm status

Теперь проведём тестирование активного-пассивного кластера или отказоустойчивости.

Можно или остановить контейнер web1 или web2 или послать команаду стоп на одном из узлов"в самом контейнере web1 или web2" crm cluster stop
Стопанем web1 контейнер.
docker stop web1

Удостоверимся что он остановлен:
docker ps -a

После чего проверим что 1 узел у нас перешел в офлайн "web1" а ресурс с vip переключился на web2.
docker exec web2 crm status

Проверяем через curl 172.16.0.10 и видим что балансировщик, ресурс и бекенд продолжает отрабатывать запросы.

Можно остановить контейнер бек1 и тогда на curl будут присылаться только сообщения <h1>Это backend2"</h1> так как работает только 2ой бекенд.
